7.6s 1 /opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5
7.6s 2 warnings.warn(f"A NumPy version >={np_minversion} and <{np_maxversion}"
25.7s 3 Epoch 1/20
26.7s 4 2023-10-23 07:26:07.293974: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape insequential/dropout/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer
26.9s 5 2023-10-23 07:26:07.293974: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape insequential/dropout/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer
46.7s 6 590/590 - 21s - loss: 0.3769 - accuracy: 0.8788 - val_loss: 0.0662 - val_accuracy: 0.9812 - lr: 0.0010 - 21s/epoch - 36ms/step
46.7s 7 Epoch 2/20
58.5s 8 590/590 - 12s - loss: 0.1368 - accuracy: 0.9595 - val_loss: 0.0407 - val_accuracy: 0.9881 - lr: 0.0010 - 12s/epoch - 20ms/step
58.5s 9 Epoch 3/20
70.3s 10 590/590 - 12s - loss: 0.1044 - accuracy: 0.9697 - val_loss: 0.0342 - val_accuracy: 0.9893 - lr: 0.0010 - 12s/epoch - 20ms/step
70.4s 11 Epoch 4/20
82.1s 12 590/590 - 12s - loss: 0.1432 - accuracy: 0.9652 - val_loss: 0.0514 - val_accuracy: 0.9852 - lr: 0.0010 - 12s/epoch - 20ms/step
82.1s 13 Epoch 5/20
94.0s 14 590/590 - 12s - loss: 0.1537 - accuracy: 0.9644 - val_loss: 0.0351 - val_accuracy: 0.9886 - lr: 0.0010 - 12s/epoch - 20ms/step
94.0s 15 Epoch 6/20
105.7s 16 590/590 - 12s - loss: 0.1379 - accuracy: 0.9684 - val_loss: 0.0341 - val_accuracy: 0.9895 - lr: 0.0010 - 12s/epoch - 20ms/step
105.7s 17 Epoch 7/20
117.7s 18 590/590 - 12s - loss: 0.1393 - accuracy: 0.9707 - val_loss: 0.0653 - val_accuracy: 0.9824 - lr: 0.0010 - 12s/epoch - 20ms/step
117.7s 19 Epoch 8/20
130.0s 20 590/590 - 12s - loss: 0.2656 - accuracy: 0.9626 - val_loss: 0.0285 - val_accuracy: 0.9919 - lr: 0.0010 - 12s/epoch - 21ms/step
130.0s 21 Epoch 9/20
142.1s 22 590/590 - 12s - loss: 0.3671 - accuracy: 0.9650 - val_loss: 0.0416 - val_accuracy: 0.9883 - lr: 0.0010 - 12s/epoch - 21ms/step
142.2s 23 Epoch 10/20
154.3s 24 590/590 - 12s - loss: 0.1544 - accuracy: 0.9655 - val_loss: 0.0289 - val_accuracy: 0.9902 - lr: 0.0010 - 12s/epoch - 21ms/step
154.3s 25 Epoch 11/20
166.4s 26 
166.4s 27 Epoch 11: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.
166.4s 28 590/590 - 12s - loss: 0.3912 - accuracy: 0.9526 - val_loss: 0.0424 - val_accuracy: 0.9876 - lr: 0.0010 - 12s/epoch - 21ms/step
166.4s 29 Epoch 12/20
178.5s 30 590/590 - 12s - loss: 0.1963 - accuracy: 0.9675 - val_loss: 0.0317 - val_accuracy: 0.9907 - lr: 5.0000e-04 - 12s/epoch - 20ms/step
178.5s 31 Epoch 13/20
190.6s 32 590/590 - 12s - loss: 0.1041 - accuracy: 0.9748 - val_loss: 0.0276 - val_accuracy: 0.9914 - lr: 5.0000e-04 - 12s/epoch - 20ms/step
190.6s 33 Epoch 14/20
202.6s 34 
202.6s 35 Epoch 14: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.
202.6s 36 590/590 - 12s - loss: 0.1086 - accuracy: 0.9758 - val_loss: 0.0289 - val_accuracy: 0.9912 - lr: 5.0000e-04 - 12s/epoch - 20ms/step
202.6s 37 Epoch 15/20
214.6s 38 590/590 - 12s - loss: 0.1050 - accuracy: 0.9783 - val_loss: 0.0222 - val_accuracy: 0.9926 - lr: 2.5000e-04 - 12s/epoch - 20ms/step
214.6s 39 Epoch 16/20
226.6s 40 590/590 - 12s - loss: 0.0971 - accuracy: 0.9787 - val_loss: 0.0244 - val_accuracy: 0.9921 - lr: 2.5000e-04 - 12s/epoch - 20ms/step
226.6s 41 Epoch 17/20
238.3s 42 590/590 - 12s - loss: 0.0735 - accuracy: 0.9804 - val_loss: 0.0248 - val_accuracy: 0.9921 - lr: 2.5000e-04 - 12s/epoch - 20ms/step
238.3s 43 Epoch 18/20
250.3s 44 
250.3s 45 Epoch 18: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.
250.3s 46 590/590 - 12s - loss: 0.0901 - accuracy: 0.9792 - val_loss: 0.0235 - val_accuracy: 0.9914 - lr: 2.5000e-04 - 12s/epoch - 20ms/step
250.3s 47 Epoch 19/20
262.1s 48 590/590 - 12s - loss: 0.1174 - accuracy: 0.9817 - val_loss: 0.0220 - val_accuracy: 0.9926 - lr: 1.2500e-04 - 12s/epoch - 20ms/step
262.2s 49 Epoch 20/20
274.1s 50 590/590 - 12s - loss: 0.0633 - accuracy: 0.9833 - val_loss: 0.0218 - val_accuracy: 0.9924 - lr: 1.2500e-04 - 12s/epoch - 20ms/step
277.4s 51 1/1182 [..............................] - ETA: 24s - loss: 0.0598 - accuracy: 0.9688  22/1182 [..............................] - ETA: 2s - loss: 0.0218 - accuracy: 0.9929   42/1182 [>.............................] - ETA: 2s - loss: 0.0205 - accuracy: 0.9933  62/1182 [>.............................] - ETA: 2s - loss: 0.0193 - accuracy: 0.9934  82/1182 [=>............................] - ETA: 2s - loss: 0.0196 - accuracy: 0.9935 102/1182 [=>............................] - ETA: 2s - loss: 0.0175 - accuracy: 0.9942 122/1182 [==>...........................] - ETA: 2s - loss: 0.0212 - accuracy: 0.9939 143/1182 [==>...........................] - ETA: 2s - loss: 0.0192 - accuracy: 0.9941 163/1182 [===>..........................] - ETA: 2s - loss: 0.0191 - accuracy: 0.9944 183/1182 [===>..........................] - ETA: 2s - loss: 0.0195 - accuracy: 0.9944 203/1182 [====>.........................] - ETA: 2s - loss: 0.0189 - accuracy: 0.9945 223/1182 [====>.........................] - ETA: 2s - loss: 0.0195 - accuracy: 0.9944 243/1182 [=====>........................] - ETA: 2s - loss: 0.0190 - accuracy: 0.9943 264/1182 [=====>........................] - ETA: 2s - loss: 0.0192 - accuracy: 0.9942 284/1182 [======>.......................] - ETA: 2s - loss: 0.0192 - accuracy: 0.9941 304/1182 [======>.......................] - ETA: 2s - loss: 0.0185 - accuracy: 0.9942 325/1182 [=======>......................] - ETA: 2s - loss: 0.0194 - accuracy: 0.9939 345/1182 [=======>......................] - ETA: 2s - loss: 0.0185 - accuracy: 0.9943 365/1182 [========>.....................] - ETA: 2s - loss: 0.0192 - accuracy: 0.9943 385/1182 [========>.....................] - ETA: 2s - loss: 0.0209 - accuracy: 0.9943 405/1182 [=========>....................] - ETA: 1s - loss: 0.0213 - accuracy: 0.9944 425/1182 [=========>....................] - ETA: 1s - loss: 0.0210 - accuracy: 0.9945 444/1182 [==========>...................] - ETA: 1s - loss: 0.0209 - accuracy: 0.9944 464/1182 [==========>...................] - ETA: 1s - loss: 0.0208 - accuracy: 0.9944 484/1182 [===========>..................] - ETA: 1s - loss: 0.0203 - accuracy: 0.9945 505/1182 [===========>..................] - ETA: 1s - loss: 0.0199 - accuracy: 0.9946 525/1182 [============>.................] - ETA: 1s - loss: 0.0195 - accuracy: 0.9946 545/1182 [============>.................] - ETA: 1s - loss: 0.0191 - accuracy: 0.9947 565/1182 [=============>................] - ETA: 1s - loss: 0.0189 - accuracy: 0.9947 585/1182 [=============>................] - ETA: 1s - loss: 0.0191 - accuracy: 0.9947 605/1182 [==============>...............] - ETA: 1s - loss: 0.0189 - accuracy: 0.9947 625/1182 [==============>...............] - ETA: 1s - loss: 0.0187 - accuracy: 0.9948 645/1182 [===============>..............] - ETA: 1s - loss: 0.0189 - accuracy: 0.9947 666/1182 [===============>..............] - ETA: 1s - loss: 0.0193 - accuracy: 0.9947 686/1182 [================>.............] - ETA: 1s - loss: 0.0192 - accuracy: 0.9947 705/1182 [================>.............] - ETA: 1s - loss: 0.0191 - accuracy: 0.9946 726/1182 [=================>............] - ETA: 1s - loss: 0.0190 - accuracy: 0.9947 747/1182 [=================>............] - ETA: 1s - loss: 0.0194 - accuracy: 0.9945 767/1182 [==================>...........] - ETA: 1s - loss: 0.0199 - accuracy: 0.9944 787/1182 [==================>...........] - ETA: 1s - loss: 0.0198 - accuracy: 0.9944 808/1182 [===================>..........] - ETA: 0s - loss: 0.0197 - accuracy: 0.9944 828/1182 [====================>.........] - ETA: 0s - loss: 0.0194 - accuracy: 0.9945 849/1182 [====================>.........] - ETA: 0s - loss: 0.0191 - accuracy: 0.9946 870/1182 [=====================>........] - ETA: 0s - loss: 0.0193 - accuracy: 0.9944 891/1182 [=====================>........] - ETA: 0s - loss: 0.0192 - accuracy: 0.9944 912/1182 [======================>.......] - ETA: 0s - loss: 0.0193 - accuracy: 0.9944 933/1182 [======================>.......] - ETA: 0s - loss: 0.0191 - accuracy: 0.9944 954/1182 [=======================>......] - ETA: 0s - loss: 0.0191 - accuracy: 0.9944 975/1182 [=======================>......] - ETA: 0s - loss: 0.0188 - accuracy: 0.9945 996/1182 [========================>.....] - ETA: 0s - loss: 0.0190 - accuracy: 0.99441017/1182 [========================>.....] - ETA: 0s - loss: 0.0190 - accuracy: 0.99441038/1182 [=========================>....] - ETA: 0s - loss: 0.0194 - accuracy: 0.99441059/1182 [=========================>....] - ETA: 0s - loss: 0.0192 - accuracy: 0.99441080/1182 [==========================>...] - ETA: 0s - loss: 0.0192 - accuracy: 0.99441101/1182 [==========================>...] - ETA: 0s - loss: 0.0194 - accuracy: 0.99431122/1182 [===========================>..] - ETA: 0s - loss: 0.0191 - accuracy: 0.99441142/1182 [===========================>..] - ETA: 0s - loss: 0.0189 - accuracy: 0.99441163/1182 [============================>.] - ETA: 0s - loss: 0.0189 - accuracy: 0.99451182/1182 [==============================] - 3s 3ms/step - loss: 0.0189 - accuracy: 0.9944
277.4s 52 Final training loss: 0.01886019
277.4s 53 Final training accuracy: 99.4444%
279.2s 54 1/875 [..............................] - ETA: 1:40 31/875 [>.............................] - ETA: 1s   63/875 [=>............................] - ETA: 1s 94/875 [==>...........................] - ETA: 1s126/875 [===>..........................] - ETA: 1s157/875 [====>.........................] - ETA: 1s189/875 [=====>........................] - ETA: 1s221/875 [======>.......................] - ETA: 1s253/875 [=======>......................] - ETA: 1s285/875 [========>.....................] - ETA: 0s316/875 [=========>....................] - ETA: 0s347/875 [==========>...................] - ETA: 0s378/875 [===========>..................] - ETA: 0s409/875 [=============>................] - ETA: 0s440/875 [==============>...............] - ETA: 0s471/875 [===============>..............] - ETA: 0s502/875 [================>.............] - ETA: 0s533/875 [=================>............] - ETA: 0s564/875 [==================>...........] - ETA: 0s597/875 [===================>..........] - ETA: 0s628/875 [====================>.........] - ETA: 0s660/875 [=====================>........] - ETA: 0s691/875 [======================>.......] - ETA: 0s722/875 [=======================>......] - ETA: 0s754/875 [========================>.....] - ETA: 0s779/875 [=========================>....] - ETA: 0s810/875 [==========================>...] - ETA: 0s841/875 [===========================>..] - ETA: 0s872/875 [============================>.] - ETA: 0s875/875 [==============================] - 2s 2ms/step
287.9s 55 /opt/conda/lib/python3.10/site-packages/traitlets/traitlets.py:2930: FutureWarning: --Exporter.preprocessors=["remove_papermill_header.RemovePapermillHeader"] for containers is deprecated in traitlets 5.0. You can pass `--Exporter.preprocessors item` ... multiple times to add items to a list.
287.9s 56 warn(
287.9s 57 [NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.
287.9s 58 [NbConvertApp] Converting notebook __notebook__.ipynb to notebook
288.4s 59 [NbConvertApp] Writing 190977 bytes to __notebook__.ipynb
290.0s 60 /opt/conda/lib/python3.10/site-packages/traitlets/traitlets.py:2930: FutureWarning: --Exporter.preprocessors=["nbconvert.preprocessors.ExtractOutputPreprocessor"] for containers is deprecated in traitlets 5.0. You can pass `--Exporter.preprocessors item` ... multiple times to add items to a list.
290.0s 61 warn(
290.0s 62 [NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.
290.0s 63 [NbConvertApp] Converting notebook __notebook__.ipynb to html
291.0s 64 [NbConvertApp] Support files will be in __results___files/
291.0s 65 [NbConvertApp] Making directory __results___files
291.0s 66 [NbConvertApp] Making directory __results___files
291.0s 67 [NbConvertApp] Making directory __results___files
291.0s 68 [NbConvertApp] Writing 303524 bytes to __results__.html